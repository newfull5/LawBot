{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import bs4\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [] # 법률 상담목\n",
    "body = [] # 질의 응답 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(url, pages):\n",
    "    \n",
    "    driver = webdriver.Chrome('C:\\Web_Driver\\chromedriver.exe')#웹 드라이버가 저장되는 경로입니다.\n",
    "    driver.implicitly_wait(1)\n",
    "    current_page = url\n",
    "    \n",
    "    driver.get(current_page)\n",
    "    \n",
    "    sleep(3)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    cnt = 0 \n",
    "\n",
    "    for k in range(2, pages):\n",
    "        for i in range(4, 24):\n",
    "            try: # 해당 목록이 끝날 경우 \n",
    "                driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[2]/div/form[1]/fieldset/table/tbody/tr[{}]/td[2]/a'.format(i)).click()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            driver.get(driver.current_url)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            title.append(driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[2]/div/div[3]/div/div[1]/div[1]/h3/a').text)\n",
    "            body.append(driver.find_element_by_class_name('boardReadBody').text)\n",
    "\n",
    "            print(title[-1])\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        try:\n",
    "            driver.get(current_page + '&page={}'.format(k))\n",
    "\n",
    "            driver.get(driver.current_url)\n",
    "        except:\n",
    "            \n",
    "            break\n",
    "    print('[+] 크롤링을 마쳤습니다. 총 파싱한 게시글 수 : {} [+]'.format(cnt))        \n",
    "    return title, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna01',10], # 가사소송\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna02',12], # 강제집행\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna03',7], # 주택임대차\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna04',4], # 상가임대차\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna05',8], # 근로관계\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna06',4], # 파산회생\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna07',42], # 민사소송\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna08',10], # 상사소송\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna09',20], # 형사소송\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna10',10], # 행정소송\n",
    "    ['http://www.freelawfirm.co.kr/index.php?mid=lawqna11',8], # 헌법소송\n",
    "]\n",
    "\n",
    "def combine(url,num):\n",
    "    global title\n",
    "    global body\n",
    "    \n",
    "    temp1,temp2 = crawling(url, num)\n",
    "    \n",
    "    title += temp1\n",
    "    body += temp2\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in urls:\n",
    "    combine(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = []\n",
    "A = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = re.compile('\\[결론\\].{5,}\\\\n     이')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(title)):\n",
    "    try:\n",
    "        if q.findall(body[i])[0]:\n",
    "            print(title[i])\n",
    "            print(q.findall(body[i])[0])\n",
    "            print()\n",
    "            Q.append(title[i])\n",
    "            A.append(q.findall(body[i])[0])\n",
    "    except:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = list(map(lambda x: x[7:], Q))\n",
    "\n",
    "A = list(map(lambda x: x[5:-7], A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbotdata = pd.DataFrame({\"Q\":Q, \"A\":A, \"label\":[3]*246440})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbotdata.to_csv('ChatbotData.csv') # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
