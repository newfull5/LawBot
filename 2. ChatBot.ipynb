{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoGPT2 | ChatBot.ipynb",
      "provenance": [],
      "mount_file_id": "1k27NTpSGYms37oWrYt43lE-6rhK3CQqc",
      "authorship_tag": "ABX9TyOZYXGkg/64Q6bENNkGFKnd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfull5/LawBot/blob/master/2.%20ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG52UxnRFKuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTqD-DNf_Hsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E4jcG4_FPog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet gluonnlp sentencepiece pandas transformers pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Tymv7vF69o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoGPT2#egg=kogpt2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H2bDVgIGecm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --recurse-submodules https://github.com/haven-jeon/KoGPT2-chatbot.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wdcL2UJGzBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd KoGPT2-chatbot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDGOKbZSG5et",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dcc46c4-c33a-48c3-a7ce-8aadc14d896e"
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python train_torch.py --train --gpus 1 --max_epochs 80"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-16 03:30:27.945420: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "INFO:root:Namespace(accumulate_grad_batches=1, amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=96, benchmark=False, chat=False, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, early_stop_callback=False, fast_dev_run=False, gpus=1, gradient_clip_val=0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_gpu_memory=None, log_save_interval=100, logger=True, lr=5e-05, max_epochs=80, max_len=32, max_steps=None, min_epochs=1, min_steps=None, model_params='model_chp/model_last.ckpt', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, overfit_pct=None, precision=32, prepare_data_per_node=True, print_nan_grads=False, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, row_log_interval=50, sentiment='0', terminate_on_nan=False, test_percent_check=None, tpu_cores=<function Trainer._arg_default at 0x7fd5aec53840>, track_grad_norm=-1, train=True, train_percent_check=None, truncated_bptt_steps=None, val_check_interval=1.0, val_percent_check=None, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n",
            "using cached model\n",
            "INFO:transformers.configuration_utils:Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "WARNING:transformers.modeling_utils:Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at None and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "INFO:lightning:GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type             | Params\n",
            "---------------------------------------------------\n",
            "0 | kogpt2        | GPT2LMHeadModel  | 124 M \n",
            "1 | loss_function | CrossEntropyLoss | 0     \n",
            "INFO:lightning:\n",
            "  | Name          | Type             | Params\n",
            "---------------------------------------------------\n",
            "0 | kogpt2        | GPT2LMHeadModel  | 124 M \n",
            "1 | loss_function | CrossEntropyLoss | 0     \n",
            "Epoch 1:   0% 0/2568 [00:00<?, ?it/s] INFO:root:contexts : 상속재산의 분할방법\n",
            "INFO:root:contexts : 사망한 부모의 빚을 물려받지 않을 수 있는지 여부\n",
            "INFO:root:toked ctx: ['<usr>', '▁상속', '재산', '의', '▁분할', '방법', '</s>', '<unused1>', '▁3', '</s>']\n",
            "INFO:root:toked ctx: ['<usr>', '▁사망한', '▁부모의', '▁빚을', '▁물려', '받지', '▁않을', '▁수', '▁있는지', '▁여부', '</s>', '<unused1>', '▁3', '</s>']\n",
            "INFO:root:response : 이상에서 살펴본 바와 같이 귀하의 경우에 상속재산의 분할에 관하여 부친이 특별히 유언을 남기지 않고 돌아가셨다면 우선 가족, 즉 공동상속인 사이의 원만한 협의에 의하여 해결하여야 합니다. 만약 협의가 성립되지 아니하는 때에는 나머지 공동상속인을 상대로 그들의 보통재판적 소재지(상대방의 주거지)나 부동산 소재지에 있는 법원에 조정신청을 할 수 있으며, 조정에 관하여 조정을 하지 아니하기로 하는 결정이 있거나, 조정이 성립되지 아니한 경우에는 제소신청에 의한 방법으로 상속재산을 분할할 수 있습니다.\n",
            "INFO:root:response : 본건에서 부친이 빚만 남겨두고 돌아가셨고, 상속포기신고기간 등이 아직 경과하지 않았다면 조속히 관할법원에 상속포기신고 또는 한정승인신고를 함으로써 상속채무에 대한 면책을 주장할 수 있을 것입니다. 다만, 주의할 것은 상속포기나 한정승인의 신청을 한 경우에도 상속인이 그 신청 후 상속재산을 은닉 또는 부정소비 하거나 고의로 재산목록에 기입하지 아니하는 등의 행위를 한 때에는 단순승인을 한 것으로 간주될 수 있습니다(민법 제1026조제3호).\n",
            "INFO:root:toked response : ['▁있거나', ',', '▁조정이', '▁성립', '되지', '▁아니', '한', '▁경우에는', '▁제소', '신청', '에', '▁의한', '▁방법으로', '▁상속', '재', '산을', '▁분할', '할', '▁수', '▁있습니다', '.', '</s>']\n",
            "INFO:root:toked response : ['▁한', '▁것으로', '▁간주', '될', '▁수', '▁있습니다', '(', '민', '법', '▁제', '10', '26', '조', '제', '3', '호', ').', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', ',', '▁조정이', '▁성립', '되지', '▁아니', '한', '▁경우에는', '▁제소', '신청', '에', '▁의한', '▁방법으로', '▁상속', '재', '산을', '▁분할', '할', '▁수', '▁있습니다', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁것으로', '▁간주', '될', '▁수', '▁있습니다', '(', '민', '법', '▁제', '10', '26', '조', '제', '3', '호', ').', '</s>']\n",
            "Epoch 1: 100% 2568/2568 [1:22:20<00:00,  1.92s/it, loss=0.019, v_num=0]/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\n",
            "Epoch 00000: loss reached 0.00725 (best 0.00725), saving model to /content/KoGPT2-chatbot/model_chp/model_epoch=00-loss=0.01.ckpt as top 1\n",
            "INFO:lightning:\n",
            "Epoch 00000: loss reached 0.00725 (best 0.00725), saving model to /content/KoGPT2-chatbot/model_chp/model_epoch=00-loss=0.01.ckpt as top 1\n",
            "Epoch 2:   0% 0/2568 [00:00<?, ?it/s, loss=0.019, v_num=0]INFO:root:contexts : 재외국민의 가족관계등록부 정정절차\n",
            "INFO:root:toked ctx: ['<usr>', '▁재외', '국민의', '▁가족', '관계', '등록', '부', '▁정정', '절차', '</s>', '<unused1>', '▁3', '</s>']\n",
            "INFO:root:response : 귀하는 등록부 정정허가신청서에 등록사항별 증명서, 재외국민등록부등본, 거류국의 외국인등록부등본(또는 영주권사본), 사유서 등을 첨부하여 재외공관의 장에게 제출하고, 그 신청서를 접수한 재외공관의 장은 이를 외교통상부장관을 경유하여 등록기준지를 관할하는 가정법원에 송부합니다(다만, 등록부 정정허가 여부는 사안에 따라 결정될 것임). 다만, 재외공관장이 등록부 기록의 착오 또는 누락된 사실을 확인하였을 때에는 그 조사확인서를 첨부하여 직접 등록기준지 관할 시(구)·읍·면장에게 송부하여 이에 관한 정정을 구할 수 있습니다(재외국민의가족관계등록창설․가족관계등록부정정 및 가족관계등록부정리에관한특례법 제5조제1항, 제6조).\n",
            "INFO:root:toked response : ['관계', '등록', '부정', '리에', '관한', '특례', '법', '▁제', '5', '조', '제', '1', '항', ',', '▁제', '6', '조', ').', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '등록', '부정', '리에', '관한', '특례', '법', '▁제', '5', '조', '제', '1', '항', ',', '▁제', '6', '조', ').', '</s>']\n",
            "INFO:root:contexts : 협의이혼을 전제한 재산분할약정의 재판상이혼 시 적용 여부\n",
            "INFO:root:toked ctx: ['<usr>', '▁협의', '이혼', '을', '▁전', '제한', '▁재산', '분할', '약', '정의', '▁재판', '상이', '혼', '▁시', '▁적용', '▁여부', '</s>', '<unused1>', '▁3', '</s>']\n",
            "INFO:root:response : 따라서 귀하는 위 약정서에 기하여 민사소송으로 위 주택의 소유권이전등기청구를 할 수는 없으며, 가정법원에 재산분할청구를 하여야 할 것입니다.\n",
            "INFO:root:toked response : ['▁가정', '법원에', '▁재산', '분할', '청', '구를', '▁하여', '야', '▁할', '▁것입니다', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '법원에', '▁재산', '분할', '청', '구를', '▁하여', '야', '▁할', '▁것입니다', '.', '</s>']\n",
            "Epoch 2: 100% 2568/2568 [1:22:23<00:00,  1.93s/it, loss=0.003, v_num=0]\n",
            "Epoch 00001: loss reached 0.00074 (best 0.00074), saving model to /content/KoGPT2-chatbot/model_chp/model_epoch=01-loss=0.00.ckpt as top 1\n",
            "INFO:lightning:\n",
            "Epoch 00001: loss reached 0.00074 (best 0.00074), saving model to /content/KoGPT2-chatbot/model_chp/model_epoch=01-loss=0.00.ckpt as top 1\n",
            "Epoch 3:   0% 0/2568 [00:00<?, ?it/s, loss=0.003, v_num=0]INFO:root:contexts : 부부일방이 명의신탁한 부동산도 재산분할청구의 대상인지 여부\n",
            "INFO:root:toked ctx: ['<usr>', '▁부부', '일', '방이', '▁명의', '신탁', '한', '▁부동산', '도', '▁재산', '분할', '청', '구의', '▁대상', '인지', '▁여부', '</s>', '<unused1>', '▁3', '</s>']\n",
            "INFO:root:response : 따라서 귀하가 청구한 재산분할청구사건에 있어서 J명의로 명의신탁 된 부동산도 귀하와 H의 재산형성에 대한 기여도를 정함에 있어서 참작할 사유로 될 수 있을 것입니다.\n",
            "INFO:root:toked response : ['▁정', '함에', '▁있어서', '▁참작', '할', '▁사유로', '▁될', '▁수', '▁있을', '▁것입니다', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '함에', '▁있어서', '▁참작', '할', '▁사유로', '▁될', '▁수', '▁있을', '▁것입니다', '.', '</s>']\n",
            "INFO:root:contexts : 협의이혼 시 자녀에 대한 양육비 약정의 효력\n",
            "INFO:root:toked ctx: ['<usr>', '▁협의', '이혼', '▁시', '▁자녀', '에', '▁대한', '▁양육', '비', '▁약', '정의', '▁효력', '</s>', '<unused1>', '▁3', '</s>']\n",
            "INFO:root:response : 따라서 부양약정의 변경, 취소에 대하여 귀하가 전남편과 별도로 협정한바 없고, 종전 약정을 변경하거나 취소할 만한 사정변경이 없는 한, 약정한대로 자녀들이 취업 또는 결혼할 때까지 귀하는 전남편에게 약정한 양육비를 청구할 수 있을 것입니다.\n",
            "INFO:root:toked response : ['▁때까지', '▁귀', '하는', '▁전남', '편', '에게', '▁약', '정한', '▁양육', '비를', '▁청구할', '▁수', '▁있을', '▁것입니다', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁귀', '하는', '▁전남', '편', '에게', '▁약', '정한', '▁양육', '비를', '▁청구할', '▁수', '▁있을', '▁것입니다', '.', '</s>']\n",
            "Epoch 3:  13% 343/2568 [11:00<1:11:26,  1.93s/it, loss=0.002, v_num=0]/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 3:  13% 343/2568 [11:02<1:11:38,  1.93s/it, loss=0.002, v_num=0]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "INFO:root:best model path /content/KoGPT2-chatbot/model_chp/model_epoch=01-loss=0.00.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3tfqAt6JNy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da9d2697-a93d-416d-c939-3ed8659de768"
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python train_torch.py --gpus 1 --chat"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-16 06:34:20.903486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "INFO:root:Namespace(accumulate_grad_batches=1, amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=96, benchmark=False, chat=True, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, early_stop_callback=False, fast_dev_run=False, gpus=1, gradient_clip_val=0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_gpu_memory=None, log_save_interval=100, logger=True, lr=5e-05, max_epochs=1000, max_len=32, max_steps=None, min_epochs=1, min_steps=None, model_params='model_chp/model_last.ckpt', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, overfit_pct=None, precision=32, prepare_data_per_node=True, print_nan_grads=False, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, row_log_interval=50, sentiment='0', terminate_on_nan=False, test_percent_check=None, tpu_cores=<function Trainer._arg_default at 0x7fce46944840>, track_grad_norm=-1, train=False, train_percent_check=None, truncated_bptt_steps=None, val_check_interval=1.0, val_percent_check=None, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
            "using cached model\n",
            "using cached model\n",
            "using cached model\n",
            "INFO:transformers.configuration_utils:Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "WARNING:transformers.modeling_utils:Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at None and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "user > 형부와 처제 간에 혼인할 수 있는지 여부\n",
            "Simsimi > 따라서 귀하는 그 가족을 상대로 혼인신고를 할 수 있을 것입니다.\n",
            "user > 유증으로 유류분이 침해된 경우 상속인의 구제\n",
            "Simsimi > 따라서 귀하의 부친의 사망일로부터 10년 내에 행사하지 아니하면 소멸합니다.\n",
            "user > 이혼한 사실이 가족관계증명서에 기재가 되는지 여부\n",
            "Simsimi > 따라서 귀하는 지금이라도 혼인관계증명서를 제출할 수 있을 것입니다.\n",
            "user > 형부와 처제 간에 혼인\n",
            "Simsimi > 따라서 귀하는 지금이라도 혼인신고를 할 수 있을 것입니다.\n",
            "user > 형부 처제 혼인\n",
            "Simsimi > 따라서 귀하는 지금이라도 이혼청구소송을 제기할 수 있을 것입니다.\n",
            "user > 형부랑 처제랑 혼인할 수 있낭?\n",
            "Simsimi > 따라서 귀하는 지금이라도 이혼할 수 있을 것입니다.\n",
            "user > 배고프다\n",
            "Simsimi > 따라서 귀하는 그 음식을 먹을 수 있을 것입니다.\n",
            "user > 그렇구나\n",
            "Simsimi > 따라서 귀하는 그 사실을 안 날로부터 3개월 내에 응분의 책임을 지게 될 것입니다.\n",
            "user > 개명절차\n",
            "Simsimi > 따라서 귀하는 귀하의 성년자이기 때문에 귀하의 성년자손의 부모님의 동의 없이 변경할 수 있습니다.\n",
            "user > 이혼절차\n",
            "Simsimi > 따라서 귀하는 지금이라도 이혼청구소송을 제기할 수 있을 것입니다.\n",
            "user > 약혼자 사기 징역 이해제\n",
            "Simsimi > 따라서 위 이혼청구소송을 하는 것이 나을 것입니다.\n",
            "user > 양자로 입양된 아이가 부모 재산을 상속할 수 있는지 여부\n",
            "Simsimi > 따라서 귀하는 부동산을 취득할 수 있을 것입니다.\n",
            "user > quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2kljXudQHRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}